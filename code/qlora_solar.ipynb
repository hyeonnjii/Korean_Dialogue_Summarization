{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da97766b",
      "metadata": {
        "id": "da97766b"
      },
      "source": [
        "### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f53321-a503-49c4-acbf-f5085329b962",
      "metadata": {
        "id": "23f53321-a503-49c4-acbf-f5085329b962",
        "outputId": "2abda5bd-e872-476a-82a5-046c737db9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cohere 5.5.3 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install -q -U transformers==4.38.2\n",
        "!pip3 install -q -U datasets==2.18.0\n",
        "!pip3 install -q -U bitsandbytes==0.42.0\n",
        "!pip3 install -q -U peft==0.9.0\n",
        "!pip3 install -q -U trl==0.7.11\n",
        "!pip3 install -q -U accelerate==0.27.2\n",
        "!pip3 install -q -U wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4cb2bdd",
      "metadata": {
        "id": "c4cb2bdd"
      },
      "source": [
        "### 데이터 다운"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c15f9b13-0a0b-48d4-a1e0-d83710bc8581",
      "metadata": {
        "id": "c15f9b13-0a0b-48d4-a1e0-d83710bc8581"
      },
      "outputs": [],
      "source": [
        "# !wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000302/data/data.tar.gz\n",
        "# !tar -xvf data.tar.gz\n",
        "# !rm -rf data.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d4816e",
      "metadata": {
        "id": "95d4816e"
      },
      "source": [
        "### 허깅페이스 로그인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bf3a3f1-4c08-4586-a825-17004b24c8f2",
      "metadata": {
        "id": "9bf3a3f1-4c08-4586-a825-17004b24c8f2",
        "outputId": "edddc9e6-fa35-4465-c2f7-10612e140b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /data/ephemeral/home/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efd845f",
      "metadata": {
        "id": "9efd845f"
      },
      "source": [
        "### WandB login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1a173f",
      "metadata": {
        "id": "fb1a173f",
        "outputId": "66ee4e15-d21f-4ace-8824-6f5eb6abe882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d38f5b3",
      "metadata": {
        "id": "3d38f5b3"
      },
      "source": [
        "### 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ce52c5-5b04-4a77-9420-6613d6c927b7",
      "metadata": {
        "id": "13ce52c5-5b04-4a77-9420-6613d6c927b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
        "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd86c7-3e6e-4d65-91d9-5548c6bb1471",
      "metadata": {
        "id": "94fd86c7-3e6e-4d65-91d9-5548c6bb1471"
      },
      "source": [
        "## 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c173dd25-e922-4982-8288-abc943827eea",
      "metadata": {
        "id": "c173dd25-e922-4982-8288-abc943827eea"
      },
      "outputs": [],
      "source": [
        "# LoRA\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "# Quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1f96f9",
      "metadata": {
        "id": "4e1f96f9"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9770b5-5424-4372-a19e-48cbd9cd6b53",
      "metadata": {
        "id": "cb9770b5-5424-4372-a19e-48cbd9cd6b53",
        "outputId": "8327659d-9857-49d1-cc64-4bc555bce11e",
        "colab": {
          "referenced_widgets": [
            "16660363ac2a4732892d39d20e689d26"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16660363ac2a4732892d39d20e689d26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_id = \"whybe-choi/OPEN-SOLAR-KO-10.7B-sum\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72531a96-fbca-45b0-99b3-4473560b7e90",
      "metadata": {
        "id": "72531a96-fbca-45b0-99b3-4473560b7e90"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f0900f-1d38-48f8-ae4a-56fd1376c8a9",
      "metadata": {
        "id": "a8f0900f-1d38-48f8-ae4a-56fd1376c8a9"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('../data/train.csv')\n",
        "valid_df = pd.read_csv('../data/dev.csv')\n",
        "test_df = pd.read_csv('../data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1f19ee-a4b1-4035-a49f-09a4a48b3433",
      "metadata": {
        "id": "fb1f19ee-a4b1-4035-a49f-09a4a48b3433",
        "outputId": "ef548676-5d53-49b8-adeb-32e9a846379c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...</td>\n",
              "      <td>스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...</td>\n",
              "      <td>건강검진 받기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>#Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...</td>\n",
              "      <td>파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...</td>\n",
              "      <td>백신</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>#Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...</td>\n",
              "      <td>#Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...</td>\n",
              "      <td>열쇠 찾기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>#Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...</td>\n",
              "      <td>#Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...</td>\n",
              "      <td>여자친구가 있다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>#Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...</td>\n",
              "      <td>말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...</td>\n",
              "      <td>댄스</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     fname                                           dialogue  \\\n",
              "0  train_0  #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나...   \n",
              "1  train_1  #Person1#: 안녕하세요, 파커 부인, 어떻게 지내셨나요?\\n#Person2#...   \n",
              "2  train_2  #Person1#: 실례합니다, 열쇠 한 묶음 보셨나요?\\n#Person2#: 어떤...   \n",
              "3  train_3  #Person1#: 왜 너는 여자친구가 있다는 걸 말해주지 않았어?\\n#Person...   \n",
              "4  train_4  #Person1#: 안녕, 숙녀분들! 오늘 밤 당신들은 정말 멋져 보여. 이 춤을 ...   \n",
              "\n",
              "                                             summary     topic  \n",
              "0  스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니...   건강검진 받기  \n",
              "1  파커 부인이 리키를 데리고 백신 접종을 하러 갔다. 피터스 박사는 기록을 확인한 후...        백신  \n",
              "2  #Person1#은 열쇠 한 묶음을 찾고 있고, 그것을 찾기 위해 #Person2#...     열쇠 찾기  \n",
              "3  #Person1#은 #Person2#가 여자친구가 있고 그녀와 결혼할 것이라는 사실...  여자친구가 있다  \n",
              "4  말릭이 니키에게 춤을 요청한다. 말릭이 발을 밟는 것을 신경 쓰지 않는다면 니키는 ...        댄스  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dev_0</td>\n",
              "      <td>#Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \\n#Person2#: 요즘...</td>\n",
              "      <td>#Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대...</td>\n",
              "      <td>의사에게 상담하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dev_1</td>\n",
              "      <td>#Person1#: 헤이, 지미. 나중에 운동하러 가자.\\n#Person2#: 그래...</td>\n",
              "      <td>#Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.</td>\n",
              "      <td>운동하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dev_2</td>\n",
              "      <td>#Person1#: 나는 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 해.\\n#...</td>\n",
              "      <td>#Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Pe...</td>\n",
              "      <td>건강한 음식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dev_3</td>\n",
              "      <td>#Person1#: UFO를 믿으세요?\\n#Person2#: 물론이죠, 그들은 저기...</td>\n",
              "      <td>#Person2#는 UFO를 믿고 꿈에서 그들을 볼 수 있다고 말한다. #Perso...</td>\n",
              "      <td>UFO와 외계인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dev_4</td>\n",
              "      <td>#Person1#: 오늘 학교에 갔어?\\n#Person2#: 당연하지. 너는?\\n#...</td>\n",
              "      <td>#Person1#은 오늘 학교에 가지 않았다. #Person2#는 내일 수업을 빼먹...</td>\n",
              "      <td>학교 가기</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fname                                           dialogue  \\\n",
              "0  dev_0  #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \\n#Person2#: 요즘...   \n",
              "1  dev_1  #Person1#: 헤이, 지미. 나중에 운동하러 가자.\\n#Person2#: 그래...   \n",
              "2  dev_2  #Person1#: 나는 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 해.\\n#...   \n",
              "3  dev_3  #Person1#: UFO를 믿으세요?\\n#Person2#: 물론이죠, 그들은 저기...   \n",
              "4  dev_4  #Person1#: 오늘 학교에 갔어?\\n#Person2#: 당연하지. 너는?\\n#...   \n",
              "\n",
              "                                             summary      topic  \n",
              "0  #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대...  의사에게 상담하기  \n",
              "1    #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.       운동하기  \n",
              "2  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Pe...     건강한 음식  \n",
              "3  #Person2#는 UFO를 믿고 꿈에서 그들을 볼 수 있다고 말한다. #Perso...   UFO와 외계인  \n",
              "4  #Person1#은 오늘 학교에 가지 않았다. #Person2#는 내일 수업을 빼먹...      학교 가기  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>dialogue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \\n#Person2#: 네, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>#Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\\n#Person2#: 또...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>#Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \\n#Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>#Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\\n#Person...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>#Person1#: 이 올림픽 공원이 정말 크네요!\\n#Person2#: 네. 지금...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fname                                           dialogue\n",
              "0  test_0  #Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \\n#Person2#: 네, ...\n",
              "1  test_1  #Person1#: 드디어 왔네! 왜 그렇게 오래 걸렸어?\\n#Person2#: 또...\n",
              "2  test_2  #Person1#: 케이트, 무슨 일이 일어났는지 너는 믿지 못할거야. \\n#Per...\n",
              "3  test_3  #Person1#: 생일 축하해, 이건 너를 위한 거야, 브라이언.\\n#Person...\n",
              "4  test_4  #Person1#: 이 올림픽 공원이 정말 크네요!\\n#Person2#: 네. 지금..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train_df.head())\n",
        "display(valid_df.head())\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11ba815-130e-442f-951f-c9b601cee317",
      "metadata": {
        "id": "f11ba815-130e-442f-951f-c9b601cee317"
      },
      "outputs": [],
      "source": [
        "# DataFrame을 Dataset으로 변환\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "valid_dataset = Dataset.from_pandas(valid_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# DatasetDict 생성\n",
        "dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'valid': valid_dataset,\n",
        "    'test': test_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad189f5-1720-4363-8ae0-10703002d20f",
      "metadata": {
        "id": "1ad189f5-1720-4363-8ae0-10703002d20f",
        "outputId": "fef63967-83cf-436f-9beb-dab3de8b95fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['fname', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12457\n",
              "    })\n",
              "    valid: Dataset({\n",
              "        features: ['fname', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['fname', 'dialogue'],\n",
              "        num_rows: 499\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45093f6c-98ac-47c6-975f-bb16b651e7eb",
      "metadata": {
        "id": "45093f6c-98ac-47c6-975f-bb16b651e7eb",
        "outputId": "4bf61196-c4c7-4607-a482-5318ef28d74e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fname': 'train_0',\n",
              " 'dialogue': '#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\\n#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\\n#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\\n#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\\n#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\\n#Person2#: 알겠습니다.\\n#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\\n#Person2#: 네.\\n#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \\n#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\\n#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\\n#Person2#: 알겠습니다, 감사합니다, 의사선생님.',\n",
              " 'summary': '스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.',\n",
              " 'topic': '건강검진 받기'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 형태 확인\n",
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb107e6",
      "metadata": {
        "id": "2cb107e6",
        "outputId": "b898b8e6-8591-4b4d-f4e0-c14a4d84a5d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['fname', 'dialogue', 'summary', 'topic'],\n",
              "    num_rows: 12457\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d871aa58-8d65-4282-af79-a36178079c77",
      "metadata": {
        "id": "d871aa58-8d65-4282-af79-a36178079c77"
      },
      "source": [
        "## 프롬프트 형태로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa21375-f131-448c-9d2d-a56218d41616",
      "metadata": {
        "id": "8fa21375-f131-448c-9d2d-a56218d41616"
      },
      "outputs": [],
      "source": [
        "def prompt_formatter(sample):\n",
        "    return f\"\"\"<s>### Instruction:\n",
        "당신은 대화를 요약해주는 유능한 AI입니다. \\\n",
        "당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. \\\n",
        "당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
        "\n",
        "### Dialogue:\n",
        "{sample['dialogue']}\n",
        "\n",
        "### Summary:\n",
        "{sample['summary']}</s>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e627a990-3673-4f81-9878-fd1fdc7a24e8",
      "metadata": {
        "id": "e627a990-3673-4f81-9878-fd1fdc7a24e8",
        "outputId": "d04f2f10-574f-4cc6-943d-31b8c55e034c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>### Instruction:\n",
            "당신은 대화를 요약해주는 유능한 AI입니다. 당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. 당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
            "\n",
            "### Dialogue:\n",
            "#Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
            "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
            "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
            "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
            "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
            "#Person2#: 알겠습니다.\n",
            "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
            "#Person2#: 네.\n",
            "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
            "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
            "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
            "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
            "\n",
            "### Summary:\n",
            "스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.</s>\n"
          ]
        }
      ],
      "source": [
        "print(prompt_formatter(dataset['train'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dd3fa6c-b484-4fe1-8c03-afef5e9043a4",
      "metadata": {
        "id": "8dd3fa6c-b484-4fe1-8c03-afef5e9043a4"
      },
      "source": [
        "## 모델 학습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf59813",
      "metadata": {
        "id": "ecf59813"
      },
      "source": [
        "### WandB 연동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45cf7b5",
      "metadata": {
        "id": "d45cf7b5",
        "outputId": "ff2b4804-6c6d-469f-980e-9fed4a3e76e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwhybe-choi\u001b[0m (\u001b[33mNLP-team3\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/data/ephemeral/home/code/wandb/run-20240526_145322-14ceofw8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8' target=\"_blank\">OPEN-SOLAR-KO-10.7B-1716735201</a></strong> to <a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B' target=\"_blank\">https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8' target=\"_blank\">https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd3404de440>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    entity='NLP-team3',\n",
        "    project='OPEN-SOLAR-KO-10.7B',\n",
        "    name=f\"OPEN-SOLAR-KO-10.7B-{str(int(time.time()))}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa958945",
      "metadata": {
        "id": "aa958945"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82881292",
      "metadata": {
        "id": "82881292",
        "outputId": "f0945519-ca7b-4c2c-e68c-be2d53a8b3ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"models\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    logging_steps=4,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=4e-4,  ### 2e-4\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    bf16=True,\n",
        "    fp16=False,\n",
        "    tf32=True,\n",
        "    max_grad_norm=1.0,\n",
        "    warmup_ratio=0.06,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    disable_tqdm=False,\n",
        "    weight_decay=0.01,\n",
        "    report_to='wandb',     # Logging에 wandb를 이용함\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset['valid'],\n",
        "    max_seq_length=1024,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    formatting_func=prompt_formatter,\n",
        "    args=args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3adab40e",
      "metadata": {
        "id": "3adab40e"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e552ee-e033-4109-8bbd-5cb1958922be",
      "metadata": {
        "id": "e3e552ee-e033-4109-8bbd-5cb1958922be",
        "outputId": "a5e3a590-bbb3-4bd3-9782-0afe46fda7c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 11:39, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.389100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.291400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.311700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.272700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.323600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.235900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.212300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.199600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.219000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.168400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=54, training_loss=1.2607893458119146, metrics={'train_runtime': 712.7872, 'train_samples_per_second': 0.61, 'train_steps_per_second': 0.076, 'total_flos': 2.7928224004571136e+16, 'train_loss': 1.2607893458119146, 'epoch': 2.92})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1a71e3",
      "metadata": {
        "id": "2e1a71e3",
        "outputId": "7cd0539a-2c98-45bc-abf8-94227d9afdc0",
        "colab": {
          "referenced_widgets": [
            "46a26f0ff33a482c856160cf0b7818c2"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a26f0ff33a482c856160cf0b7818c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▂▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▃▁▂▁▁▁▃▄▅▆█▇▇</td></tr><tr><td>train/learning_rate</td><td>███▇▆▆▅▄▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▆▆▅▄▆▃▂▂▃▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>2.92</td></tr><tr><td>train/global_step</td><td>54</td></tr><tr><td>train/grad_norm</td><td>0.39534</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1684</td></tr><tr><td>train/total_flos</td><td>2.7928224004571136e+16</td></tr><tr><td>train/train_loss</td><td>1.26079</td></tr><tr><td>train/train_runtime</td><td>712.7872</td></tr><tr><td>train/train_samples_per_second</td><td>0.61</td></tr><tr><td>train/train_steps_per_second</td><td>0.076</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">OPEN-SOLAR-KO-10.7B-1716735201</strong> at: <a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8' target=\"_blank\">https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B/runs/14ceofw8</a><br/> View project at: <a href='https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B' target=\"_blank\">https://wandb.ai/NLP-team3/OPEN-SOLAR-KO-10.7B</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240526_145322-14ceofw8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# wandb 종료\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4945a50d",
      "metadata": {
        "id": "4945a50d"
      },
      "outputs": [],
      "source": [
        "ADAPTER_MODEL = \"lora_adapter\"\n",
        "\n",
        "trainer.model.save_pretrained(ADAPTER_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f349d9bd",
      "metadata": {
        "id": "f349d9bd"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00274209",
      "metadata": {
        "id": "00274209",
        "outputId": "b29e16d7-0a5e-4c3b-b66c-aeed623d71cf",
        "colab": {
          "referenced_widgets": [
            "5f70c45dda2447c982d8ebf822389707"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f70c45dda2447c982d8ebf822389707",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id = \"whybe-choi/OPEN-SOLAR-KO-10.7B-sum\"\n",
        "ADAPTER_MODEL = \"lora_adapter\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', torch_dtype=torch.float16)\n",
        "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
        "\n",
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5699704b",
      "metadata": {
        "id": "5699704b",
        "outputId": "0824d02d-698b-4db7-9666-282d0200bff7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('OPEN-SOLAR-KO-10.7B-sum-val/tokenizer_config.json',\n",
              " 'OPEN-SOLAR-KO-10.7B-sum-val/special_tokens_map.json',\n",
              " 'OPEN-SOLAR-KO-10.7B-sum-val/tokenizer.json')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model.save_pretrained('OPEN-SOLAR-KO-10.7B-sum-val')\n",
        "tokenizer.save_pretrained('OPEN-SOLAR-KO-10.7B-sum-val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f7c0ae",
      "metadata": {
        "id": "19f7c0ae"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df00567",
      "metadata": {
        "id": "7df00567",
        "outputId": "b1050f7d-5f56-4782-fa84-97f4d6dde058",
        "colab": {
          "referenced_widgets": [
            "f81dc27c75dd41448c6a1497270e8e21",
            "f081e80581a342278e98a57ee94ad077",
            "c8814a268fb941d1beebb4be5d3f40b6",
            "def439990dc34f44b9f13366403e9abb",
            "b4b6cb63e6ea4bc780d7b80fca9d7a48",
            "a1a55e35732e465c9850822a599e9319",
            "9f594174c7e84201b028044ee989ef25"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f81dc27c75dd41448c6a1497270e8e21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f081e80581a342278e98a57ee94ad077",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8814a268fb941d1beebb4be5d3f40b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00005.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def439990dc34f44b9f13366403e9abb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4b6cb63e6ea4bc780d7b80fca9d7a48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00005.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1a55e35732e465c9850822a599e9319",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f594174c7e84201b028044ee989ef25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/whybe-choi/OPEN-SOLAR-KO-10.7B-sum-val/commit/86c7412e4a64a7a6bb284b04b3d5218a279a0b06', commit_message='Upload tokenizer', commit_description='', oid='86c7412e4a64a7a6bb284b04b3d5218a279a0b06', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_SAVE_HUB_PATH = 'whybe-choi/OPEN-SOLAR-KO-10.7B-sum-val' # 여기에 {본인의 허깅페이스 허브}/{저장하고자 하는 이름} 형태로 작성\n",
        "HUGGINGFACE_AUTH_TOKEN = '' # 허깅페이스 write token\n",
        "\n",
        "model.push_to_hub(\n",
        "   MODEL_SAVE_HUB_PATH,\n",
        "   use_temp_dir=True,\n",
        "   use_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
        ")\n",
        "tokenizer.push_to_hub(\n",
        "   MODEL_SAVE_HUB_PATH,\n",
        "   use_temp_dir=True,\n",
        "   use_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4c1c10",
      "metadata": {
        "id": "3e4c1c10"
      },
      "source": [
        "## 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329344ca",
      "metadata": {
        "id": "329344ca"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078b2702",
      "metadata": {
        "id": "078b2702"
      },
      "outputs": [],
      "source": [
        "# Quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda96000",
      "metadata": {
        "id": "eda96000",
        "outputId": "cf25d641-6f5f-4540-f069-1142c956fe86",
        "colab": {
          "referenced_widgets": [
            "d07abef470d14bb9aff1305ea8aa6fe5",
            "1bbd3903da6b48a08db65ce00b1edb6b",
            "6a321cf65cd740f5bdec13f8d2e865fd",
            "e6fe6c92012c4e2cb716e516d600f09e",
            "dc5fa36ef5394d5583d4a08ca026bf35"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07abef470d14bb9aff1305ea8aa6fe5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bbd3903da6b48a08db65ce00b1edb6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a321cf65cd740f5bdec13f8d2e865fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/87.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6fe6c92012c4e2cb716e516d600f09e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.59M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc5fa36ef5394d5583d4a08ca026bf35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "FINETUNE_MODEL = \"whybe-choi/OPEN-SOLAR-KO-10.7B-sum-val\"\n",
        "\n",
        "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, low_cpu_mem_usage=True, quantization_config=bnb_config, device_map=\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(FINETUNE_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a03055f",
      "metadata": {
        "id": "7a03055f"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9bfbaf3",
      "metadata": {
        "id": "c9bfbaf3"
      },
      "outputs": [],
      "source": [
        "pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=192)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4f1c8e",
      "metadata": {
        "id": "3c4f1c8e"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['dialogue'])):\n",
        "        prompt = f\"\"\"<s>### Instruction:\n",
        "당신은 대화를 요약해주는 유능한 AI입니다. \\\n",
        "당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. \\\n",
        "당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
        "\n",
        "### Dialogue:\n",
        "{example['dialogue'][i]}\n",
        "\n",
        "### Summary:\n",
        "\"\"\"\n",
        "        output_texts.append(prompt)\n",
        "    return output_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5790a9",
      "metadata": {
        "id": "3f5790a9",
        "outputId": "565e515d-2658-47e9-da2f-897fb7f9d9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>### Instruction:\n",
            "당신은 대화를 요약해주는 유능한 AI입니다. 당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. 당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
            "\n",
            "### Dialogue:\n",
            "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
            "#Person2#: 네, 실장님...\n",
            "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
            "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
            "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
            "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
            "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
            "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
            "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
            "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
            "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
            "#Person2#: 그게 다신가요?\n",
            "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
            "\n",
            "### Summary:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_data = dataset['test']\n",
        "print(generate_prompt(test_data[:1])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96afc53b",
      "metadata": {
        "id": "96afc53b",
        "outputId": "5201b21d-2ea1-44ca-fa8d-9d88c1442a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "더슨 씨는 #Person1#의 지시로 내부 및 외부 통신 모두에 적용되는 새로운 정책에 대한 메모를 작성하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "prompt = generate_prompt(test_data[:1])[0]\n",
        "\n",
        "outputs = pipe_finetuned(\n",
        "    prompt,\n",
        "    do_sample=True,\n",
        "    temperature=0.1,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.1,\n",
        ")\n",
        "summary = outputs[0][\"generated_text\"][len(prompt):]\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57d79b7",
      "metadata": {
        "id": "b57d79b7",
        "outputId": "07dab1e6-0f33-441c-ef43-0245ba47139a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/499 [00:02<19:45,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
            "#Person2#: 네, 실장님...\n",
            "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
            "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
            "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
            "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
            "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
            "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
            "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
            "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
            "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
            "#Person2#: 그게 다신가요?\n",
            "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
            "========================= [ 요약 ] =========================\n",
            "더슨 씨는 #Person1#의 지시로 내부 및 외부 통신 모두에 적용되는 새로운 정책에 대한 메모를 작성하고 있습니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 51/499 [02:15<20:45,  2.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 택시!\n",
            "#Person2#: 어디로 가시겠습니까, 손님?\n",
            "#Person1#: 프렌드십 호텔이요.\n",
            "#Person2#: 알겠습니다, 여기서 멀지 않아요.\n",
            "#Person1#: 중요한 일이 있어서, 속도를 높일 수 있나요?\n",
            "#Person2#: 네, 최선을 다하겠습니다. 도착했습니다.\n",
            "#Person1#: 정말 빠르네요! 얼마나 내야 하나요?\n",
            "#Person2#: 미터기에는 15위안이 나옵니다.\n",
            "#Person1#: 여기 20위안 있습니다, 거스름돈은 가지세요.\n",
            "#Person2#: 정말 감사합니다.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#이 #Person2#의 택시에 타고, #Person2#는 #Person1#을 빠르게 목적지로 데려다 준다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 101/499 [04:25<15:49,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 트럼프가 다시 우리 대통령이 된다면 상상도 할 수 없어요.\n",
            "#Person2#: 그가 우리 대통령이라는 것을 자랑스럽게 생각하고, 그가 다시 선출되면 정말 행복할 것입니다.\n",
            "#Person1#: 당신이 그를 위해 투표했죠?\n",
            "#Person2#: 당신이 그를 위해 투표했나요, 왜냐하면 저는 그렇게 했거든요.\n",
            "#Person1#: 이에 대해 확신할 수 없어요.\n",
            "#Person2#: 저는 트럼프에게 믿음밖에 없어요.\n",
            "#Person1#: 뭐라고요?\n",
            "#Person2#: 나는 그가 다시 한 번 미국을 위대하게 만들 것이라고 확신합니다!\n",
            "#Person1#: 음, 우리나라에는 변화가 필요하긴 하지만, 그가 올바른 사람이라고는 생각하지 않아요.\n",
            "#Person2#: 우리나라는 이미 변화하고 있어요.\n",
            "#Person1#: 이 부분에 대해서는 동의해요.\n",
            "#Person2#: 나는 그가 우리나라를 잘 돌볼 것이라고 믿습니다.\n",
            "#Person1#: 음, 저는 그렇게 생각하지 않아요. 어쨌든 저는 바이든에게 투표할 거예요.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#과 #Person2#는 트럼프에 대한 의견을 공유하지만, 그들은 서로 다른 후보에게 투표할 예정입니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 151/499 [06:32<13:20,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 무슨 일이야?\n",
            "#Person2#: 제 컴퓨터에 어떤 종류의 바이러스가 침투한 것 같아, 이 이메일을 보낼 수가 없어. 텍스트 포트 번호를 알고 있니?\n",
            "#Person1#: 내가 컴퓨터를 한번 볼 수 있을까?\n",
            "#Person2#: 물론이지, 고마워.\n",
            "#Person1#: 음, 바이러스와는 관련이 없어. 첨부파일이 좀 큰 게 문제야. 이메일 용량을 초과했어.\n",
            "#Person2#: 알겠어. 그럼 이제 어떻게 해야 하지?\n",
            "#Person1#: 압축해서 보내면 돼.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person2#는 #Person1#에게 컴퓨터 문제를 해결해달라고 요청한다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 201/499 [08:43<18:02,  3.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 아, 배가 고파 죽겠어요. 중국은 처음인데 진짜 중국 요리를 먹어보고 싶어요. 무엇을 추천하시겠어요?\n",
            "#Person2#: 상황에 따라 다릅니다. 중국에는 유명한 요리가 여덟 가지가 있는데, 예를 들어, 사천 요리와 후난 요리가 그에 속합니다.\n",
            "#Person1#: 무척 맵다고 들었어요.\n",
            "#Person2#: 맞습니다. 매운 음식을 좋아하시면 몇 가지 드셔 보실 수 있습니다.\n",
            "#Person1#: 못 먹어요. 미국에서 먹었다가 거의 죽을 뻔했어요.\n",
            "#Person2#: 다음으로는 광동 요리와 강소 요리가 있습니다. 사람들이 대부분 좋아합니다.\n",
            "#Person1#: 오, 광동 요리 먹어보고 싶어요. 어디죠? 먼가요?\n",
            "#Person2#: 제가 아는 곳은 반 시간 정도 걸립니다.\n",
            "#Person1#: 너무 멀어요. 저는 지금 배가 너무 고파요. 여기 호텔에 식당이 있나요?\n",
            "#Person2#: 죄송합니다. 우리 호텔에는 없습니다. 하지만 근처에 있는 곳을 알고 있습니다.\n",
            "#Person1#: 어떤 요리인가요?\n",
            "#Person2#: 베이징 요리입니다. 베이징 오리 구이로 유명합니다.\n",
            "#Person1#: 오, 예. 많이 들어봤어요. 꼭 먹어보고 싶어요. 어디서 먹을 수 있나요?\n",
            "#Person2#: 가장 좋은 곳은 당연히 전취덕 식당입니다.\n",
            "#Person1#: 이 근처에 있나요?\n",
            "#Person2#: 네, 걸어서 15분, 차로 5분 걸립니다. 교통이 막히지 않는다면요.\n",
            "#Person1#: 알려주셔서 감사합니다. 식당 이름이 뭐라고 하셨죠?\n",
            "#Person2#: 종이에 적어드릴게요. 택시 기사에게 보여주거나 길을 물어보세요.\n",
            "#Person1#: 정말 친절하시네요. 감사합니다.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#은 배고프다. #Person2#는 #Person1#에게 다양한 중국 요리에 대해 이야기한다. #Person1#은 베이징 요리를 먹고 싶어하고, #Person2#는 #Person1#에게 베이징 오리 구이를 제공하는 전취덕 식당을 소개한다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 251/499 [10:47<09:49,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 안녕하세요. 특별히 티켓을 찾으러 왔습니다. 지난달에 예약했습니다. 이것이 제 예약 확인서입니다.\n",
            "#Person2#: 정말 죄송합니다. 최근에 재확인하러 오지 않으셨습니다. 국제선이기 때문에 티켓을 찾으러 오셨어야 했는데, 72시간 이내에 재확인하지 않는 모든 예약은 취소됩니다.\n",
            "#Person1#: 하지만 이틀 동안 너무 바빴습니다. 그럼, 다른 티켓이 있나요? 다음 것을 원합니다.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#은 #Person2#에게 티켓을 찾으러 왔지만, #Person2#는 #Person1#의 예약을 취소했다고 말했습니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 301/499 [12:59<07:27,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 이 문제에 대해 가능한 한 빨리 비상 회의를 소집해야 합니다.\n",
            "#Person2#: 네. 회의 메모를 보내겠습니다.\n",
            "#Person1#: 켄이 돌아오면 오늘 오후로 일정을 잡으세요.\n",
            "#Person2#: 오늘 그가 돌아올 것 같지 않아요.\n",
            "#Person1#: 아, 그렇군요. 그래도 진행해주세요. 나중에 그에게 설명할게요. 어떤 경우에도 이 주문을 잃어선 안 됩니다!\n",
            "#Person2#: 압니다, 이건 큰 거니까요.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#은 #Person2#에게 긴급 회의를 소집하도록 요청합니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 351/499 [15:04<06:55,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 실례합니다, 아가씨.\n",
            "#Person2#: 무엇을 도와드릴까요?\n",
            "#Person1#: 방금 제 비행기가 지연되었다는 안내를 들었습니다.\n",
            "#Person2#: 비행기 번호가 어떻게 되나요?\n",
            "#Person1#: 청두행 CA216 비행기입니다.\n",
            "#Person2#: 네, 맞습니다. 지연되었습니다.\n",
            "#Person1#: 왜 그런지 알려주실 수 있나요?\n",
            "#Person2#: 네, 그럼요. 지연은 폭우 때문입니다.\n",
            "#Person1#: 지연이 얼마나 될까요? 더 자세한 정보가 있으신가요?\n",
            "#Person2#: 죄송합니다, 현재로서는 지연 정도를 알 수 없습니다. 하지만 최근 일기예보에 의하면, 곧 날씨에 변화가 있을 거라고 합니다.\n",
            "#Person1#: 기다려야겠군요. 그럼, 정오 전에 비가 그칠 가능성이 있나요?\n",
            "#Person2#: 확실하게 말씀드리기 어렵습니다. 여름에는 날씨가 매우 변덕스럽거든요. 최근 비행 안내 방송을 꼭 들어보세요.\n",
            "#Person1#: 네, 그렇게 하겠습니다. 감사합니다. 안녕히 계세요!\n",
            "#Person2#: 안녕히 가세요.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person1#은 #Person2#에게 청두행 CA216 비행기의 지연 이유를 묻는다. #Person2#는 폭우 때문이라고 말하고, #Person1#에게 비행 안내 방송을 듣도록 제안한다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 401/499 [17:12<04:27,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 안녕하세요. 세입자 지원 센터입니다.\n",
            "#Person2#: 안녕하세요. 제 집주인과 문제가 있어요. 집주인은 충분히 좋은 사람이지만, 그와 저는 수리 비용에 대해 합의를 이루지 못하고 있어요.\n",
            "#Person1#: 그가 수리를 하지 않는 것인가요?\n",
            "#Person2#: 그가 수리를 하지 않는 것은 아니에요. 그냥 너무 오래 걸려요. 처음에 이사 왔을 때, 히터가 고장나서 3개월이나 걸려서 수리했고, 지난달에 제 30번째 생일이었어요. 친구들이 저에게 놀랄만한 파티를 열어줬어요. 많은 음식과 맥주를 가지고 왔고, 심지어 록 앤 롤 밴드까지 있었어요. 밤새도록 파티를 했고.\n",
            "#Person1#: 그리고 이웃들이 소음에 대해 불평을 했나요.\n",
            "#Person2#: 아니요, 건물에 있는 모든 사람들이 왔어요. 정말 멋진 파티였어요. 불행히도, 몇몇 사람들이 실수로 거실 창문을 깨뜨렸어요. 다음 날, 저는 수리공을 불러서 창문을 고쳤어요. 그가 이미 여기에 있었기 때문에, 저는 그에게 2개월 이상 집주인에게 불평하고 있던 고장난 세탁기를 고치게 했어요. 그리고 지난 주, 저는 수리 비용을 제외하고 집에 대한 돈을 우편으로 보냈어요. 하지만 오늘 아침, 집주인이 화를 내며 전화해서 그가 수리 비용을 지불하지 않겠다고 했어요. 그게 공정해 보이지 않아요. 제가 어떻게 해야 할까요?\n",
            "========================= [ 요약 ] =========================\n",
            "#Person2#는 #Person1#에게 집주인이 수리 비용을 지불하지 않고 있다고 말합니다. #Person2#는 이것이 불공정하다고 생각하고 #Person1#에게 어떻게 해야 할지 묻습니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 451/499 [19:29<02:07,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================= [ 대화 ] =========================\n",
            "#Person1#: 실례합니다.\n",
            "#Person2#: 네?\n",
            "#Person1#: 피크 트램까지 어떻게 가는지 알려주실 수 있나요?\n",
            "#Person2#: 물론입니다. 퀸스 로드를 따라가세요...\n",
            "#Person1#: 퀸스 로드를 따라...\n",
            "#Person2#: 네, 그리고 힐튼 호텔에서 오른쪽으로 꺾으세요.\n",
            "#Person1#: 힐튼에서 오른쪽으로.\n",
            "#Person2#: 그런 다음 가든 로드를 따라 올라가서 대성당을 지나가세요.\n",
            "#Person1#: 대성당이요?\n",
            "#Person2#: 네. 그 다음 신호등에서 길을 건너세요. 피크 트램은 바로 앞에 있습니다. 찾을 수 있을 거예요.\n",
            "#Person1#: 정말 친절하시네요. 감사합니다. 어... 연필 가지고 계신가요?\n",
            "#Person2#: 네. 왜요?\n",
            "#Person1#: 그 방법을 다시 한 번 말해주실 수 있나요? 적어두는 게 좋을 것 같아요.\n",
            "========================= [ 요약 ] =========================\n",
            "#Person2#는 #Person1#에게 피크 트램으로 가는 길을 알려줍니다. #Person1#은 #Person2#의 도움을 받아 메모할 예정입니다.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 499/499 [21:31<00:00,  2.59s/it]\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
        "prompts = generate_prompt(dataset['test'])\n",
        "\n",
        "for idx, prompt in enumerate(tqdm(prompts)):\n",
        "    outputs = pipe_finetuned(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        temperature=0.1,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.1,\n",
        "    )\n",
        "    summary = outputs[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "    if idx % 50 == 0:\n",
        "        print(\"=\"*25, \"[ 대화 ]\", \"=\"*25)\n",
        "        print(dataset['test'][idx][\"dialogue\"])\n",
        "        print(\"=\"*25, \"[ 요약 ]\", \"=\"*25)\n",
        "        print(summary)\n",
        "        print()\n",
        "\n",
        "    submission.loc[idx, 'summary'] = summary.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c3707b",
      "metadata": {
        "id": "f7c3707b"
      },
      "outputs": [],
      "source": [
        "submission.to_csv(\"../submission_solar.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14420527",
      "metadata": {
        "id": "14420527"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}